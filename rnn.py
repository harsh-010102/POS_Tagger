# -*- coding: utf-8 -*-
"""RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GVjO7LAFdg8oPi0MydWg92dMUEiNl5f2
"""


import nltk
nltk.download('punkt')

import torch
from nltk import word_tokenize
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from conllu import parse_incr
from sklearn.preprocessing import OneHotEncoder

from collections import Counter
import numpy as np
device = "cuda" if torch.cuda.is_available() else "cpu"
# p= 3
# s = 3
# c1
# embedding_dim = 200
# num_layers = 2
# bidirectional = True
# hidden_dim = 10
# epoch = 10
# c2
# embedding_dim = 400
# num_layers = 3
# bidirectional = True
# hidden_dim = 20
# epoch = 10
# c3
embedding_dim = 200
num_layers = 4
bidirectional = True
hidden_dim = 10
epoch = 10

def read_file(file_path):
    pos_tags_set = [] 
    sentences = []  
    with open(file_path, "r", encoding="utf-8") as f:
        for tokenlist in parse_incr(f):
            tokens = [token['form'] for token in tokenlist]
            pos_tags = [token['upostag'] for token in tokenlist]
            for i in pos_tags:
                pos_tags_set.append(i)
            sentences.append((tokens, pos_tags))
    return pos_tags_set, sentences




pos_tags_set_train, training_data = read_file(r'C:\Users\Harsh\Desktop\NLP\Assignment-2\en_atis-ud-train.conllu')
pos_tags_set_val, validation_data = read_file(r'C:\Users\Harsh\Desktop\NLP\Assignment-2\en_atis-ud-dev.conllu')
pos_tags_set_test, test_data = read_file(r'C:\Users\Harsh\Desktop\NLP\Assignment-2\en_atis-ud-test.conllu')


count = 0
pos_tags_set_train_dict = {}
for pos in pos_tags_set_train:
    if pos in pos_tags_set_train_dict:
        continue
    pos_tags_set_train_dict[pos] = count
    count += 1
idx_to_pos = dict()
for key, val in pos_tags_set_train_dict.items():
    idx_to_pos[val] = key


word_freq_of_train = dict()
for sentence, tags in training_data:
    for word in sentence:
        if word in word_freq_of_train:
            word_freq_of_train[word] += 1
        else:
            word_freq_of_train[word] = 1
train_vocab = dict()
train_vocab['<s>'] = 0
train_vocab['</s>'] = 1
train_vocab['<unk>'] = 2
train_vocab['<pad>'] = 3

for word in word_freq_of_train:
    if word_freq_of_train[word] >= 3 and word not in train_vocab:
        train_vocab[word] = len(train_vocab)
# print(train_vocab)

def get_context_tag_pair(data, p, s):
    context_li = []
    for words, tag_sequence in data:
        word = []
        tag = []
        for i in range(len(words)):
            if tag_sequence[i] == 'SYM':
                # print('yes')
                continue
            word.append(words[i])
            tag.append(tag_sequence[i])
        context_li.append([word, tag])
    return context_li

context_li_train = get_context_tag_pair(training_data, 3, 3)

context_li_val = get_context_tag_pair(validation_data, 3, 3)

context_li_test = get_context_tag_pair(test_data, 3, 3)

# print(context_li_test[0][0])
# print(context_li_test[0][1])

# print(len(context_li_test))

def get_one_hot_encoding(pos_tags):
    pos_tags_embeddings = [[1.0 if i == j else 0.0 for j in range(len(pos_tags))] for i in range(len(pos_tags))]

    return pos_tags_embeddings

pos_tags_set_train = list(pos_tags_set_train_dict.keys())

one_hot_embedding_of_pos = get_one_hot_encoding(pos_tags_set_train)
one_hot_embedding_of_pos_dict = dict()
for i in range(len(pos_tags_set_train)):
    one_hot_embedding_of_pos_dict[pos_tags_set_train[i]] = one_hot_embedding_of_pos[i]
# print(one_hot_embedding_of_pos_dict)

class POSDataset(Dataset):
    def __init__(self, vocab, pos, sentences):
        super().__init__()
        self.vocab = vocab
        self.pos = pos
        self.sentences = sentences

    def __len__(self):
        return len(self.sentences)

    def __getitem__(self, idx):
        word_context = []
        # for i in range(len(self.sentences[idx])):
        pos_tag = self.sentences[idx][1]
        pos_emb_list = []
        for i in range(len(pos_tag)):
            pos_emb = self.pos[pos_tag[i]]
            pos_emb_list.append(pos_emb)
        word_context = []
        for word in self.sentences[idx][0]:
            if word in self.vocab:
                word_context.append(self.vocab[word])
            else:
                word_context.append(self.vocab['<unk>'])
        return torch.tensor(word_context), torch.tensor(pos_emb_list)

    def collate(self, batch: list[tuple[torch.Tensor, torch.Tensor]]) :
        sentences = [i[0] for i in batch]
        labels = [i[1] for i in batch]
        padded_sentences = torch.nn.utils.rnn.pad_sequence(sentences, batch_first=True, padding_value=self.vocab["<pad>"])
        padded_labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=torch.tensor(0))
        return padded_sentences, padded_labels

train_dataset = POSDataset(train_vocab, pos_tags_set_train_dict, context_li_train)
train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=train_dataset.collate)

val_dataset = POSDataset(train_vocab, pos_tags_set_train_dict, context_li_val)
val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=val_dataset.collate)

test_dataset = POSDataset(train_vocab, pos_tags_set_train_dict, context_li_test)
test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=test_dataset.collate)

class LSTMTagger(torch.nn.Module):
    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size, num_layers=1, bidirectional=False):
        super(LSTMTagger, self).__init__()
        
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.bidirectional = bidirectional
        
        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)

        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional)
        
        if bidirectional:
            self.hidden2tag = torch.nn.Linear(hidden_dim * 2, target_size)
        else:
            self.hidden2tag = torch.nn.Linear(hidden_dim, target_size)
        
    def forward(self, sentence):
        embeds = self.word_embeddings(sentence)
        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))
        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))
        tag_scores = torch.nn.functional.log_softmax(tag_space, dim=1)
        return tag_scores
    
    def predict(self, sentence):
        with torch.no_grad():
            output = self.forward(sentence)
            return torch.argmax(output, dim=1)

rnn_model = LSTMTagger(embedding_dim, hidden_dim, len(train_vocab), len(pos_tags_set_train), num_layers, bidirectional)
loss_fn = torch.nn.CrossEntropyLoss() # use ignore index to ignore losses for padding value indices
# optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)
optimizer = torch.optim.Adam(rnn_model.parameters(), lr=0.001)

for epoch_num in range(epoch):
    # Put model in training mode
    rnn_model.train()
    error = 0
    for batch_num, (words, tags) in enumerate(train_loader):
        for index, sentence in enumerate(words):
            pred = rnn_model(sentence)
            loss = loss_fn(pred, tags[index])
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

        error += loss.item()
    print("epoch no. =", epoch_num , "loss : ", error)
def evaluate(model, data_loader):
    rnn_model.eval()
    total_correct = 0
    total_count = 0
    predicted_li = []
    tag_li = []
    with torch.no_grad():
        for batch_num, (words, tags) in enumerate(data_loader):
            for index, sentence in enumerate(words):
                output = model(sentence)
                _, predicted = torch.max(output, 1)
                for i in predicted:
                    predicted_li.append(i)
                for i in tags[index]:
                    tag_li.append(i)
                total_correct += (predicted == tags[index]).sum().item()
                total_count += len(tags[index])  # Update total count with the batch size

    val_accuracy = total_correct / total_count
    return val_accuracy, predicted_li, tag_li

evaluate(rnn_model, test_loader)

dev_accuracy, dev_predicted_val_list, dev_target_tag_values_list = evaluate(rnn_model, val_loader)
test_accuracy, test_predicted_val_list, test_target_tag_values_list = evaluate(rnn_model, test_loader)
evaluate(rnn_model, val_loader)
evaluate(rnn_model, test_loader)
# print(dev_accuracy, test_accuracy)

torch.save(rnn_model.state_dict(), 'model2.pt')


from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
dev_accuracy = accuracy_score(dev_target_tag_values_list, dev_predicted_val_list)
dev_classification_report = classification_report(dev_target_tag_values_list, dev_predicted_val_list)
dev_confusion_matrix = confusion_matrix(dev_target_tag_values_list, dev_predicted_val_list)

print("Dev Accuracy:", dev_accuracy)

print("Dev Classification Report:\n", dev_classification_report)
print("Dev Confusion Matrix:\n", dev_confusion_matrix)

test_accuracy = accuracy_score(test_target_tag_values_list, test_predicted_val_list)
test_classification_report = classification_report(test_target_tag_values_list, test_predicted_val_list)
test_confusion_matrix = confusion_matrix(test_target_tag_values_list, test_predicted_val_list)


print("Test Accuracy:", test_accuracy)
print("Test Classification Report:\n", test_classification_report)
print("Test Confusion Matrix:\n", test_confusion_matrix)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support

# Accuracy
dev_accuracy = accuracy_score(dev_target_tag_values_list, dev_predicted_val_list)
test_accuracy = accuracy_score(test_target_tag_values_list, test_predicted_val_list)

# Classification report (includes precision, recall, F1-score)
dev_report = classification_report(dev_target_tag_values_list, dev_predicted_val_list, output_dict=True)
test_report = classification_report(test_target_tag_values_list, test_predicted_val_list, output_dict=True)

# Calculate precision, recall, f1-score using confusion matrix
dev_precision, dev_recall, dev_f1, _ = precision_recall_fscore_support(dev_target_tag_values_list, dev_predicted_val_list, average='micro')
test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(test_target_tag_values_list, test_predicted_val_list, average='micro')

dev_precision_macro, dev_recall_macro, dev_f1_macro, _ = precision_recall_fscore_support(dev_target_tag_values_list, dev_predicted_val_list, average='macro')
test_precision_macro, test_recall_macro, test_f1_macro, _ = precision_recall_fscore_support(test_target_tag_values_list, test_predicted_val_list, average='macro')

# Confusion matrices
dev_conf_matrix = confusion_matrix(dev_target_tag_values_list, dev_predicted_val_list)
test_conf_matrix = confusion_matrix(test_target_tag_values_list, test_predicted_val_list)

# Print or visualize the results
print("Development Set Metrics:")
print("Accuracy:", dev_accuracy)
print("Precision (Micro) on Development Set:", dev_precision)
print("Recall (Micro) on Development Set:", dev_recall)
print("F1-score (Micro) on Development Set:", dev_f1)
print("Precision (Macro) on Development Set:", dev_precision_macro)
print("Recall (Macro) on Development Set:", dev_recall_macro)
print("F1-score (Macro) on Development Set:", dev_f1_macro)
# print("Confusion Matrix:\n", dev_conf_matrix)

print("\nTest Set Metrics:")
print("Accuracy:", test_accuracy)
print("Precision (Micro) on Test Set:", test_precision)
print("Recall (Micro) on Test Set:", test_recall)
print("F1-score (Micro) on Test Set:", test_f1)
print("Precision (Macro) on Test Set:", test_precision_macro)
print("Recall (Macro) on Test Set:", test_recall_macro)
print("F1-score (Macro) on Test Set:", test_f1_macro)
# print("Confusion Matrix:\n", test_conf_matrix)

with open('rnn_acc_c3.txt', 'a') as f:
   f.write(f"{epoch}, {dev_accuracy}\n")

